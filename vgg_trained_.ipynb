{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg trained .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP6HNI7bCQFB0AY1fJ1ejWH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkathole/plant-disease-detection/blob/main/vgg_trained_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyuHaPB16oDE"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split  \n",
        "\n",
        "N_IMAGES=400\n",
        "data_dir = '/content/drive/My Drive/data/train'\n",
        "categories=['Tomato__Target_Spot','Tomato__Tomato_mosaic_virus','Tomato_Bacterial_spot',\n",
        "            'Tomato_Early_blight','Tomato_healthy','Tomato_Late_blight','Tomato_Leaf_Mold']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF_3S9JK6o9V"
      },
      "source": [
        "data=[]\n",
        "def make_data():\n",
        "    for category in categories:\n",
        "        path=os.path.join(data_dir,category)\n",
        "        label=categories.index(category)\n",
        "        \n",
        "        for img_name in os.listdir(path)[:N_IMAGES]:\n",
        "            image_path=os.path.join(path,img_name)\n",
        "            image=cv2.imread(image_path)\n",
        "            \n",
        "            try:\n",
        "                image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                image=cv2.resize(image,(224,224))\n",
        "                \n",
        "                image=np.array(image,dtype=np.float32)\n",
        "                data.append([image,label])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "    pik=open('data.pickle','wb')\n",
        "    pickle.dump(data,pik)\n",
        "    pik.close()\n",
        "    print(len(data))\n",
        "\n",
        "make_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htd1B6wL6wEI"
      },
      "source": [
        "def load_data():\n",
        "    pick=open('data.pickle','rb')\n",
        "    data=pickle.load(pick)\n",
        "    pick.close()\n",
        "    \n",
        "    np.random.shuffle(data)\n",
        "    \n",
        "    feature=[]\n",
        "    labels=[]\n",
        "    \n",
        "    for img,label in data:\n",
        "        feature.append(img)\n",
        "        labels.append(label)\n",
        "    \n",
        "    feature=np.array(feature,dtype=np.float32)\n",
        "    labels=np.array(labels)\n",
        "    feature=feature/255.0\n",
        "    \n",
        "    return[feature,labels]\n",
        "\n",
        "load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmnTtQw362PR"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "model_vgg = VGG16(weights='imagenet', include_top=False, input_shape= (224,224,3))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDPKYUo0628I"
      },
      "source": [
        "model_vgg.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM2teAWm66Ho"
      },
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "# Adding pre-trained model layers\n",
        "model.add(model_vgg)\n",
        "\n",
        "# Flattening the image pixels\n",
        "model.add(Flatten())\n",
        "\n",
        "# Adding 2 dense layers with 4096 neurons\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "\n",
        "# Adding an output layer with 2 neurons\n",
        "model.add(Dense(7, activation='sigmoid'))\n",
        "\n",
        "# Getting the structure of our model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1EB56gz7fay"
      },
      "source": [
        "feature, label = load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQwHgm7U7iSR"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(feature, label, test_size=0.1, shuffle=True)\n",
        "\n",
        "x_train, x_test = tf.cast(x_train, tf.float32), tf.cast(x_test, tf.float32)\n",
        "\n",
        "train_dataset= tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "train_dataset = train_dataset.batch(batch_size= 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgMcvRJJ683R"
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDLv6plx7BUA"
      },
      "source": [
        "history = model.fit_generator(steps_per_epoch=100, generator=training_data, verbose=1, validation_data=testing_data, epochs=10 )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW_63quV7G6Z"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot(history):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
        "    axes[0].plot(history.history['loss'])   \n",
        "    axes[0].plot(history.history['val_loss'])\n",
        "    axes[0].legend(['loss','val_loss'])\n",
        "\n",
        "    axes[1].plot(history.history['accuracy'])   \n",
        "    axes[1].plot(history.history['val_accuracy'])\n",
        "    axes[1].legend(['accuracy','accuracy'])\n",
        "\n",
        "plot(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82eB7AL67KPw"
      },
      "source": [
        "model.save('myVggModel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-xCudyU7K_p"
      },
      "source": [
        "model = tf.keras.models.load_model('myVggModel.h5',compile=False)\n",
        "\n",
        "\n",
        "prediction = model(x_test[0:9])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC4bvzJA7QmZ"
      },
      "source": [
        "plt.figure(figsize=(9,9))\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.xlabel('Pedicted:%s\\n Actual: %s'%(categories[np.argmax(prediction[i])],\n",
        "                                           categories[y_test[i]]))\n",
        "    plt.xticks([])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}